{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a93ad3f",
   "metadata": {},
   "source": [
    "# SVM Assignment Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e64242d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  7.1592e+00  6.0250e+02  4e+04  3e+00  2e+04\n",
      " 1:  2.1840e+02 -8.6176e+02  1e+03  7e-02  4e+02\n",
      " 2:  1.3725e+02 -9.0183e+01  2e+02  1e-02  5e+01\n",
      " 3:  4.8478e+01 -1.5479e+01  6e+01  3e-03  1e+01\n",
      " 4:  2.4467e+01 -2.7209e+00  3e+01  1e-03  6e+00\n",
      " 5:  1.1255e+01  3.8462e+00  7e+00  3e-04  1e+00\n",
      " 6:  7.9712e+00  5.4852e+00  2e+00  6e-05  3e-01\n",
      " 7:  6.9506e+00  5.9990e+00  1e+00  2e-05  9e-02\n",
      " 8:  6.5698e+00  6.1903e+00  4e-01  2e-06  1e-02\n",
      " 9:  6.4094e+00  6.2999e+00  1e-01  5e-07  3e-03\n",
      "10:  6.3622e+00  6.3341e+00  3e-02  9e-08  5e-04\n",
      "11:  6.3477e+00  6.3454e+00  2e-03  4e-09  2e-05\n",
      "12:  6.3465e+00  6.3464e+00  2e-04  1e-10  7e-07\n",
      "13:  6.3464e+00  6.3464e+00  4e-06  3e-12  1e-08\n",
      "Optimal solution found.\n",
      "Validation Accuracy: 96.96%\n",
      "Test Accuracy: 96.80%\n",
      "Debugging information saved to question2.txt\n"
     ]
    }
   ],
   "source": [
    "# Question 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvxopt\n",
    "\n",
    "def svm_train_primal(data_train, label_train, regularisation_para_C):\n",
    "    # Data dimensions\n",
    "    N, d = data_train.shape\n",
    "\n",
    "    # Convert labels from {0, 1} to {-1, 1}\n",
    "    y = np.where(label_train == 0, -1, 1).reshape(-1, 1)\n",
    "\n",
    "    # Prepare matrices for cvxopt\n",
    "    P = cvxopt.matrix(np.block([[np.eye(d), np.zeros((d, N + 1))],\n",
    "                                [np.zeros((N + 1, d + N + 1))]]))  # Quadratic term\n",
    "    q = cvxopt.matrix(np.hstack([np.zeros(d + 1), regularisation_para_C / N * np.ones(N)]))  # Linear term\n",
    "    G = cvxopt.matrix(np.block([[-np.diag(y.flatten()) @ data_train, -y, -np.eye(N)],\n",
    "                                [np.zeros((N, d + 1)), -np.eye(N)]]))  # Constraints matrix\n",
    "    h = cvxopt.matrix(np.hstack([-np.ones(N), np.zeros(N)]))  # Constraints vector\n",
    "\n",
    "    # Solve the QP problem using cvxopt\n",
    "    solution = cvxopt.solvers.qp(P, q, G, h)\n",
    "    w_b_xi = np.array(solution['x']).flatten()\n",
    "\n",
    "    # Extract weight vector (w), bias term (b), and slack variables (xi)\n",
    "    w = w_b_xi[:d]\n",
    "    b = w_b_xi[d]\n",
    "    xi = w_b_xi[d+1:]  # Slack variables\n",
    "\n",
    "    return (w, b, xi)\n",
    "\n",
    "def svm_predict_primal(data_test, label_test, svm_model):\n",
    "    w, b = svm_model[:2]  # Ignore slack variables for prediction\n",
    "    # Predict: sign(w.T * X + b)\n",
    "    predictions = np.sign(np.dot(data_test, w) + b)\n",
    "    # Convert {-1, 1} back to {0, 1}\n",
    "    predictions = np.where(predictions == -1, 0, 1)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(predictions == label_test)\n",
    "    return accuracy\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load data without any assumptions about headers\n",
    "    train_data = pd.read_csv('train.csv', header=None)\n",
    "    test_data = pd.read_csv('test.csv', header=None)\n",
    "\n",
    "    # Separate features and labels\n",
    "    X_train = train_data.iloc[:4000, 1:].values  # Features from 2nd column onwards\n",
    "    y_train = train_data.iloc[:4000, 0].values   # Labels from 1st column\n",
    "    X_val = train_data.iloc[4000:, 1:].values\n",
    "    y_val = train_data.iloc[4000:, 0].values\n",
    "    X_test = test_data.iloc[:, 1:].values\n",
    "    y_test = test_data.iloc[:, 0].values\n",
    "\n",
    "    # Train the model\n",
    "    C = 100\n",
    "    svm_model = svm_train_primal(X_train, y_train, C)\n",
    "\n",
    "    # Validate and test the model\n",
    "    val_accuracy = svm_predict_primal(X_val, y_val, svm_model)\n",
    "    test_accuracy = svm_predict_primal(X_test, y_test, svm_model)\n",
    "\n",
    "    print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "    print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Sum of weights for a quick check\n",
    "    w_sum = np.sum(svm_model[0])\n",
    "    b = svm_model[1]\n",
    "    xi = svm_model[2]\n",
    "\n",
    "    # Save the debugging information to a text file\n",
    "    with open('question2.txt', 'w') as f:\n",
    "        f.write(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\\n\")\n",
    "        f.write(f\"Test Accuracy: {test_accuracy * 100:.2f}%\\n\")\n",
    "        f.write(f\"Sum of w: {w_sum}\\n\")\n",
    "        f.write(f\"Bias (b): {b}\\n\")\n",
    "        f.write(f\"Regularization parameter (C): {C}\\n\")\n",
    "        f.write(f\"Slack variables (xi): {xi[:5]} (first 5 shown)\\n\")  # To get an idea of the slack\n",
    "        f.write(f\"Total number of slack variables: {len(xi)}\\n\")\n",
    "        f.write(f\"Full Model Weights: {svm_model[0][:5]} (first 5 shown)\\n\")  # First 5 weights as a check\n",
    "\n",
    "    print(f\"Debugging information saved to question2.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c0475f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.8416e+02 -2.2800e+02  4e+04  1e+02  5e-13\n",
      " 1: -2.2204e+01 -2.2367e+02  1e+03  3e+00  5e-13\n",
      " 2: -1.2704e+01 -1.3798e+02  2e+02  4e-01  7e-14\n",
      " 3: -8.2452e+00 -4.8671e+01  6e+01  1e-01  2e-14\n",
      " 4: -6.5928e+00 -2.4543e+01  3e+01  4e-02  1e-14\n",
      " 5: -5.8533e+00 -1.1273e+01  7e+00  1e-02  9e-15\n",
      " 6: -5.9382e+00 -7.9755e+00  2e+00  2e-03  9e-15\n",
      " 7: -6.1146e+00 -6.9517e+00  1e+00  7e-04  9e-15\n",
      " 8: -6.2067e+00 -6.5700e+00  4e-01  1e-04  9e-15\n",
      " 9: -6.3032e+00 -6.4094e+00  1e-01  2e-05  9e-15\n",
      "10: -6.3347e+00 -6.3622e+00  3e-02  4e-06  1e-14\n",
      "11: -6.3454e+00 -6.3477e+00  2e-03  1e-07  1e-14\n",
      "12: -6.3464e+00 -6.3465e+00  2e-04  5e-09  1e-14\n",
      "13: -6.3464e+00 -6.3464e+00  4e-06  1e-10  1e-14\n",
      "Optimal solution found.\n",
      "Sum of alpha saved to question3.txt: 7.281637057117684\n",
      "Number of support vectors: 392\n",
      "First 5 support vector indices: [ 0 16 28 29 41]\n",
      "Number of margin violators: 392\n"
     ]
    }
   ],
   "source": [
    "# Question 3\n",
    "import cvxpy as cvx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cvxopt import matrix, solvers\n",
    "\n",
    "def svm_train_dual(data_train, label_train, regularisation_para_C):\n",
    "    samples, features = data_train.shape\n",
    "    label_train = label_train * 2 - 1  # Convert 0/1 to -1/1\n",
    "\n",
    "    # Compute the Gram matrix (dot products between training samples)\n",
    "    X = np.dot(data_train, data_train.T)\n",
    "    \n",
    "    # Set up the parameters for the quadratic program\n",
    "    P = matrix(np.outer(label_train, label_train) * X)\n",
    "    Q = matrix(-np.ones(samples))\n",
    "    G = matrix(np.vstack((-np.eye(samples), np.eye(samples))))\n",
    "    H = matrix(np.hstack((np.zeros(samples), np.ones(samples) * regularisation_para_C / samples)))\n",
    "    A = matrix(label_train, (1, samples), 'd')\n",
    "    B = matrix(0.0)\n",
    "\n",
    "    # Solve the quadratic program using cvxopt\n",
    "    solution = solvers.qp(P, Q, G, H, A, B)\n",
    "\n",
    "    # Extract the Lagrange multipliers (alpha) from the solution\n",
    "    alpha = np.ravel(solution['x'])\n",
    "\n",
    "    # Return alpha (dual solution)\n",
    "    return alpha, X\n",
    "\n",
    "# Load the training data and test data\n",
    "train_data = pd.read_csv('train.csv', header=None)\n",
    "test_data = pd.read_csv('test.csv', header=None)\n",
    "validation_data = train_data[4000:]\n",
    "train_data = train_data[:4000]\n",
    "regularisation_para_C = 100\n",
    "\n",
    "# Separate features and labels for training data\n",
    "label_train = train_data.iloc[:, 0].values  # Labels are in the first column\n",
    "data_train = train_data.iloc[:, 1:].values  # Features are in the remaining columns\n",
    "\n",
    "# Compute the dual solution\n",
    "alpha, gram_matrix = svm_train_dual(data_train, label_train, regularisation_para_C)\n",
    "\n",
    "# Calculate additional debugging information\n",
    "alpha_sum = np.sum(alpha)\n",
    "non_zero_alphas = np.sum(alpha > 1e-5)  # Approximate number of support vectors\n",
    "alpha_first_five = alpha[:5]  # First 5 alpha values\n",
    "support_vector_indices = np.where(alpha > 1e-5)[0]  # Indices of support vectors\n",
    "violating_alphas = np.where((alpha > 1e-5) & (alpha < regularisation_para_C))[0]  # Margin violators\n",
    "\n",
    "# Sum of slack variables (indirectly derived from alpha)\n",
    "slack_sum = np.sum(alpha[violating_alphas])\n",
    "\n",
    "# Debugging Gram Matrix\n",
    "gram_matrix_sample = gram_matrix[:5, :5]  # Small sample of the Gram matrix for validation\n",
    "\n",
    "# Save the debugging information to a text file\n",
    "with open('question3.txt', 'w') as f:\n",
    "    f.write(f\"Sum of alpha: {alpha_sum}\\n\")\n",
    "    f.write(f\"Number of non-zero alphas (Support Vectors): {non_zero_alphas}\\n\")\n",
    "    f.write(f\"First 5 alpha values: {alpha_first_five}\\n\")\n",
    "    f.write(f\"Regularization parameter (C): {regularisation_para_C}\\n\")\n",
    "    f.write(f\"Support Vector Indices (first 5): {support_vector_indices[:5]}\\n\")\n",
    "    f.write(f\"Number of Violating Alphas (Margin Violators): {len(violating_alphas)}\\n\")\n",
    "    f.write(f\"Sum of Slack Variables (derived from alpha): {slack_sum}\\n\")\n",
    "    f.write(f\"Gram Matrix Sample (5x5):\\n{gram_matrix_sample}\\n\")\n",
    "\n",
    "print(f\"Sum of alpha saved to question3.txt: {alpha_sum}\")\n",
    "print(f\"Number of support vectors: {non_zero_alphas}\")\n",
    "print(f\"First 5 support vector indices: {support_vector_indices[:5]}\")\n",
    "print(f\"Number of margin violators: {len(violating_alphas)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06720f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.8416e+02 -2.2800e+02  4e+04  1e+02  5e-13\n",
      " 1: -2.2204e+01 -2.2367e+02  1e+03  3e+00  5e-13\n",
      " 2: -1.2704e+01 -1.3798e+02  2e+02  4e-01  7e-14\n",
      " 3: -8.2452e+00 -4.8671e+01  6e+01  1e-01  2e-14\n",
      " 4: -6.5928e+00 -2.4543e+01  3e+01  4e-02  1e-14\n",
      " 5: -5.8533e+00 -1.1273e+01  7e+00  1e-02  9e-15\n",
      " 6: -5.9382e+00 -7.9755e+00  2e+00  2e-03  9e-15\n",
      " 7: -6.1146e+00 -6.9517e+00  1e+00  7e-04  9e-15\n",
      " 8: -6.2067e+00 -6.5700e+00  4e-01  1e-04  9e-15\n",
      " 9: -6.3032e+00 -6.4094e+00  1e-01  2e-05  9e-15\n",
      "10: -6.3347e+00 -6.3622e+00  3e-02  4e-06  1e-14\n",
      "11: -6.3454e+00 -6.3477e+00  2e-03  1e-07  1e-14\n",
      "12: -6.3464e+00 -6.3465e+00  2e-04  5e-09  1e-14\n",
      "13: -6.3464e+00 -6.3464e+00  4e-06  1e-10  1e-14\n",
      "Optimal solution found.\n",
      "Sum of w*: -0.1451352273951927\n",
      "b*: 1.7798092093688218\n",
      "Number of support vectors: 392\n",
      "First 5 weights: [-0.02622559 -0.11417209  0.04186253 -0.05229907  0.07552307]\n",
      "First 5 alpha values: [2.49999998e-02 1.76599916e-10 1.27338214e-10 1.76758740e-10\n",
      " 2.34799685e-10]\n"
     ]
    }
   ],
   "source": [
    "# Question 4\n",
    "import cvxpy as cvx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cvxopt import matrix, solvers\n",
    "\n",
    "def svm_train_dual(data_train, label_train, regularisation_para_C):\n",
    "    samples, features = data_train.shape\n",
    "    label_train = label_train * 2 - 1  # Convert 0/1 to -1/1\n",
    "    X = np.dot(data_train, data_train.T)\n",
    "    \n",
    "    P = matrix(np.outer(label_train, label_train) * X)\n",
    "    Q = matrix(-np.ones(samples))\n",
    "    G = matrix(np.vstack((-np.eye(samples), np.eye(samples))))\n",
    "    H = matrix(np.hstack((np.zeros(samples), np.ones(samples) * regularisation_para_C/samples)))\n",
    "    A = matrix(label_train, (1,samples), 'd')\n",
    "    B = matrix(0.0)\n",
    "    solution = solvers.qp(P,Q,G,H,A,B)\n",
    "    alpha = np.ravel(solution['x'])\n",
    "    return {'alpha': alpha}\n",
    "\n",
    "def compute_primal_solution(alpha, data_train, label_train, regularisation_para_C, tolerance=1e-5):\n",
    "    support_vector_indices = np.where((alpha > tolerance) & (alpha < regularisation_para_C))[0]\n",
    "    label_train = label_train * 2 - 1 \n",
    "    \n",
    "    w_star = np.sum((alpha * label_train).reshape(-1, 1) * data_train, axis=0)\n",
    "    \n",
    "    b_star_values = []\n",
    "    for idx in support_vector_indices:\n",
    "        x_s = data_train[idx]\n",
    "        y_s = label_train[idx]\n",
    "        b_star_value = y_s - np.dot(w_star, x_s)\n",
    "        b_star_values.append(b_star_value)\n",
    "    \n",
    "    # Average the bias terms from all support vectors\n",
    "    b_star = np.median(b_star_values) if b_star_values else 0\n",
    "    \n",
    "    return w_star, b_star, support_vector_indices\n",
    "\n",
    "# Load the training and test data\n",
    "train_data = pd.read_csv('train.csv', header=None)\n",
    "test_data = pd.read_csv('test.csv', header=None)\n",
    "validation_data = train_data[4000:]\n",
    "train_data = train_data[:4000]\n",
    "regularisation_para_C = 100\n",
    "label_train = train_data.iloc[:, 0].values  \n",
    "data_train = train_data.iloc[:, 1:].values \n",
    "label_test = test_data.iloc[:, 0].values  \n",
    "data_test = test_data.iloc[:, 1:].values \n",
    "\n",
    "# Train the SVM model using the dual solution\n",
    "optimal = svm_train_dual(data_train, label_train, regularisation_para_C)\n",
    "np.save('alpha.npy', optimal['alpha'])\n",
    "alpha = np.load('alpha.npy')\n",
    "\n",
    "# Compute the primal solution (w*, b*)\n",
    "w_star, b_star, support_vector_indices = compute_primal_solution(alpha, data_train, label_train, regularisation_para_C)\n",
    "\n",
    "# Calculate the sum of w_star (the weight vector)\n",
    "w_star_sum = np.sum(w_star)\n",
    "\n",
    "# Additional debugging information\n",
    "num_support_vectors = len(support_vector_indices)\n",
    "first_5_weights = w_star[:5]  # First 5 weights\n",
    "first_5_alphas = alpha[:5]     # First 5 alphas\n",
    "\n",
    "# Print the sum of w*, b*, and other relevant info to the terminal\n",
    "print(\"Sum of w*:\", w_star_sum)\n",
    "print(\"b*:\", b_star)\n",
    "print(f\"Number of support vectors: {num_support_vectors}\")\n",
    "print(f\"First 5 weights: {first_5_weights}\")\n",
    "print(f\"First 5 alpha values: {first_5_alphas}\")\n",
    "\n",
    "# Save the detailed debugging information to a text file\n",
    "with open('question4.txt', 'w') as f:\n",
    "    f.write(f\"Sum of w*: {w_star_sum}\\n\")\n",
    "    f.write(f\"b*: {b_star}\\n\")\n",
    "    f.write(f\"Number of support vectors: {num_support_vectors}\\n\")\n",
    "    f.write(f\"Support Vector Indices (first 5): {support_vector_indices[:5]}\\n\")\n",
    "    f.write(f\"First 5 weights of w*: {first_5_weights}\\n\")\n",
    "    f.write(f\"First 5 alpha values: {first_5_alphas}\\n\")\n",
    "    f.write(f\"Regularization parameter (C): {regularisation_para_C}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "109a14fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.8416e+02 -2.2800e+02  4e+04  1e+02  5e-13\n",
      " 1: -2.2204e+01 -2.2367e+02  1e+03  3e+00  5e-13\n",
      " 2: -1.2704e+01 -1.3798e+02  2e+02  4e-01  7e-14\n",
      " 3: -8.2452e+00 -4.8671e+01  6e+01  1e-01  2e-14\n",
      " 4: -6.5928e+00 -2.4543e+01  3e+01  4e-02  1e-14\n",
      " 5: -5.8533e+00 -1.1273e+01  7e+00  1e-02  9e-15\n",
      " 6: -5.9382e+00 -7.9755e+00  2e+00  2e-03  9e-15\n",
      " 7: -6.1146e+00 -6.9517e+00  1e+00  7e-04  9e-15\n",
      " 8: -6.2067e+00 -6.5700e+00  4e-01  1e-04  9e-15\n",
      " 9: -6.3032e+00 -6.4094e+00  1e-01  2e-05  9e-15\n",
      "10: -6.3347e+00 -6.3622e+00  3e-02  4e-06  1e-14\n",
      "11: -6.3454e+00 -6.3477e+00  2e-03  1e-07  1e-14\n",
      "12: -6.3464e+00 -6.3465e+00  2e-04  5e-09  1e-14\n",
      "13: -6.3464e+00 -6.3464e+00  4e-06  1e-10  1e-14\n",
      "Optimal solution found.\n",
      "Number of support vectors: 392\n",
      "Support vector indices: [   0   16   28   29   41   54   58   68   80   88  127  130  140  145\n",
      "  147  150  199  208  239  253  263  266  275  281  284  296  305  307\n",
      "  332  344  356  377  395  401  403  405  414  420  424  432  433  441\n",
      "  446  450  473  479  495  510  521  525  532  547  561  563  564  567\n",
      "  576  581  587  595  604  610  637  642  656  660  678  703  708  709\n",
      "  725  736  737  752  768  774  796  799  809  816  821  826  834  843\n",
      "  844  856  861  873  905  909  932  935  948  965  967  988  989  993\n",
      " 1003 1017 1022 1050 1082 1098 1116 1123 1139 1142 1166 1167 1178 1179\n",
      " 1188 1219 1242 1266 1274 1295 1304 1320 1364 1371 1374 1377 1403 1406\n",
      " 1407 1414 1416 1437 1447 1474 1475 1478 1489 1492 1493 1531 1532 1536\n",
      " 1539 1555 1571 1592 1594 1598 1604 1616 1627 1635 1636 1651 1659 1664\n",
      " 1667 1672 1675 1680 1683 1684 1691 1692 1705 1706 1722 1724 1737 1775\n",
      " 1778 1780 1799 1825 1833 1835 1840 1848 1851 1852 1854 1859 1862 1864\n",
      " 1865 1869 1884 1886 1889 1890 1900 1921 1924 1957 1964 1972 1982 1993\n",
      " 2012 2021 2032 2035 2039 2047 2049 2051 2064 2066 2070 2088 2099 2100\n",
      " 2108 2112 2132 2136 2145 2167 2186 2189 2215 2249 2257 2263 2269 2278\n",
      " 2281 2283 2288 2289 2306 2309 2316 2352 2356 2360 2361 2374 2390 2406\n",
      " 2407 2416 2436 2438 2446 2452 2458 2482 2490 2497 2513 2518 2544 2546\n",
      " 2550 2558 2570 2575 2620 2622 2624 2642 2645 2647 2648 2658 2688 2691\n",
      " 2699 2703 2705 2711 2715 2718 2725 2728 2734 2751 2770 2813 2817 2857\n",
      " 2861 2874 2876 2885 2902 2905 2910 2919 2925 2937 2945 2953 2964 2978\n",
      " 2998 3003 3014 3018 3052 3056 3066 3072 3079 3082 3083 3099 3111 3127\n",
      " 3145 3159 3165 3180 3188 3198 3203 3205 3212 3216 3232 3244 3248 3284\n",
      " 3297 3326 3362 3364 3369 3371 3372 3376 3389 3397 3404 3414 3423 3429\n",
      " 3456 3462 3465 3467 3472 3481 3483 3485 3510 3517 3519 3533 3535 3558\n",
      " 3562 3564 3575 3588 3589 3596 3599 3607 3611 3613 3649 3651 3659 3672\n",
      " 3684 3687 3712 3725 3734 3735 3740 3752 3772 3809 3811 3835 3844 3845\n",
      " 3846 3869 3893 3905 3916 3925 3930 3942 3950 3953 3969 3985 3990 3991]\n"
     ]
    }
   ],
   "source": [
    "# Question 5\n",
    "import cvxpy as cvx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cvxopt import matrix, solvers\n",
    "\n",
    "def svm_train_dual(data_train, label_train, regularisation_para_C):\n",
    "    samples, features = data_train.shape\n",
    "    label_train = label_train * 2 - 1  # Convert 0/1 to -1/1\n",
    "    X = np.dot(data_train, data_train.T)\n",
    "    \n",
    "    P = matrix(np.outer(label_train, label_train) * X)\n",
    "    Q = matrix(-np.ones(samples))\n",
    "    G = matrix(np.vstack((-np.eye(samples), np.eye(samples))))\n",
    "    H = matrix(np.hstack((np.zeros(samples), np.ones(samples) * regularisation_para_C/samples)))\n",
    "    A = matrix(label_train, (1,samples), 'd')\n",
    "    B = matrix(0.0)\n",
    "    solution = solvers.qp(P,Q,G,H,A,B)\n",
    "    alpha = np.ravel(solution['x'])\n",
    "    return {'alpha': alpha}\n",
    "\n",
    "def compute_primal_solution(alpha, data_train, label_train, regularisation_para_C, tolerance=1e-5):\n",
    "    support_vector_indices = np.where((alpha > tolerance) & (alpha < regularisation_para_C))[0]\n",
    "    label_train = label_train * 2 - 1 \n",
    "    \n",
    "    w_star = np.sum((alpha * label_train).reshape(-1, 1) * data_train, axis=0)\n",
    "    \n",
    "    print(f\"Number of support vectors: {len(support_vector_indices)}\")\n",
    "    print(\"Support vector indices:\", support_vector_indices)\n",
    "    \n",
    "    b_star_values = []\n",
    "    for idx in support_vector_indices:\n",
    "        x_s = data_train[idx]\n",
    "        y_s = label_train[idx]\n",
    "        b_star_value = y_s - np.dot(w_star, x_s)\n",
    "        b_star_values.append(b_star_value)\n",
    "    \n",
    "    # Write support vectors to file\n",
    "    with open('question5.txt', 'w') as f:\n",
    "        f.write(f\"Number of support vectors: {len(support_vector_indices)}\\n\")\n",
    "        f.write(f\"Support vector indices: {support_vector_indices.tolist()}\\n\")\n",
    "    \n",
    "    return w_star, None  # b_star removed\n",
    "\n",
    "train_data = pd.read_csv('train.csv', header=None)\n",
    "test_data = pd.read_csv('test.csv', header=None)\n",
    "validation_data = train_data[4000:]\n",
    "train_data = train_data[:4000]\n",
    "regularisation_para_C = 100\n",
    "label_train = train_data.iloc[:, 0].values  \n",
    "data_train = train_data.iloc[:, 1:].values \n",
    "label_test = test_data.iloc[:, 0].values  \n",
    "data_test = test_data.iloc[:, 1:].values \n",
    "optimal = svm_train_dual(data_train, label_train, regularisation_para_C)\n",
    "np.save('alpha.npy', optimal['alpha'])\n",
    "alpha = np.load('alpha.npy')\n",
    "w_star, _ = compute_primal_solution(alpha, data_train, label_train, regularisation_para_C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86bdd80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.8416e+02 -2.2800e+02  4e+04  1e+02  5e-13\n",
      " 1: -2.2204e+01 -2.2367e+02  1e+03  3e+00  5e-13\n",
      " 2: -1.2704e+01 -1.3798e+02  2e+02  4e-01  7e-14\n",
      " 3: -8.2452e+00 -4.8671e+01  6e+01  1e-01  2e-14\n",
      " 4: -6.5928e+00 -2.4543e+01  3e+01  4e-02  1e-14\n",
      " 5: -5.8533e+00 -1.1273e+01  7e+00  1e-02  9e-15\n",
      " 6: -5.9382e+00 -7.9755e+00  2e+00  2e-03  9e-15\n",
      " 7: -6.1146e+00 -6.9517e+00  1e+00  7e-04  9e-15\n",
      " 8: -6.2067e+00 -6.5700e+00  4e-01  1e-04  9e-15\n",
      " 9: -6.3032e+00 -6.4094e+00  1e-01  2e-05  9e-15\n",
      "10: -6.3347e+00 -6.3622e+00  3e-02  4e-06  1e-14\n",
      "11: -6.3454e+00 -6.3477e+00  2e-03  1e-07  1e-14\n",
      "12: -6.3464e+00 -6.3465e+00  2e-04  5e-09  1e-14\n",
      "13: -6.3464e+00 -6.3464e+00  4e-06  1e-10  1e-14\n",
      "Optimal solution found.\n",
      "Sum of alpha: 7.281637057117684\n",
      "Number of support vectors: 392\n",
      "First 5 alpha values: [2.49999998e-02 1.76599916e-10 1.27338214e-10 1.76758740e-10\n",
      " 2.34799685e-10]\n",
      "Number of margin violators (slack variables): 392\n"
     ]
    }
   ],
   "source": [
    "# Question 6\n",
    "import cvxpy as cvx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cvxopt import matrix, solvers\n",
    "\n",
    "def svm_train_dual(data_train, label_train, regularisation_para_C):\n",
    "    samples, features = data_train.shape\n",
    "    label_train = label_train * 2 - 1  # Convert 0/1 to -1/1\n",
    "\n",
    "    # Compute the Gram matrix (dot products between training samples)\n",
    "    X = np.dot(data_train, data_train.T)\n",
    "    \n",
    "    # Set up the parameters for the quadratic program\n",
    "    P = matrix(np.outer(label_train, label_train) * X)\n",
    "    Q = matrix(-np.ones(samples))\n",
    "    G = matrix(np.vstack((-np.eye(samples), np.eye(samples))))\n",
    "    H = matrix(np.hstack((np.zeros(samples), np.ones(samples) * regularisation_para_C / samples)))\n",
    "    A = matrix(label_train, (1, samples), 'd')\n",
    "    B = matrix(0.0)\n",
    "\n",
    "    # Solve the quadratic program using cvxopt\n",
    "    solution = solvers.qp(P, Q, G, H, A, B)\n",
    "\n",
    "    # Extract the Lagrange multipliers (alpha) from the solution\n",
    "    alpha = np.ravel(solution['x'])\n",
    "\n",
    "    # Return alpha and Gram matrix (for debugging)\n",
    "    return alpha, X\n",
    "\n",
    "# Load the training and test data\n",
    "train_data = pd.read_csv('train.csv', header=None)\n",
    "test_data = pd.read_csv('test.csv', header=None)\n",
    "validation_data = train_data[4000:]\n",
    "train_data = train_data[:4000]\n",
    "regularisation_para_C = 100\n",
    "\n",
    "# Separate features and labels for training data\n",
    "label_train = train_data.iloc[:, 0].values  # Labels are in the first column\n",
    "data_train = train_data.iloc[:, 1:].values  # Features are in the remaining columns\n",
    "\n",
    "# Compute the dual solution and Gram matrix\n",
    "alpha, gram_matrix = svm_train_dual(data_train, label_train, regularisation_para_C)\n",
    "\n",
    "# Save the computed alpha to a file for future use\n",
    "np.save('alpha.npy', alpha)\n",
    "\n",
    "# Sum of alpha values\n",
    "alpha_sum = np.sum(alpha)\n",
    "\n",
    "# Define a small threshold to identify support vectors (non-zero alphas)\n",
    "threshold = 1e-5\n",
    "support_vectors_indices = np.where(alpha > threshold)[0]\n",
    "support_vectors_count = len(support_vectors_indices)\n",
    "\n",
    "# First 5 alpha values\n",
    "first_5_alphas = alpha[:5]\n",
    "\n",
    "# Number of slack variables (those between 0 and C)\n",
    "violating_alphas = np.where((alpha > threshold) & (alpha < regularisation_para_C))[0]\n",
    "slack_variable_count = len(violating_alphas)\n",
    "\n",
    "# Debugging Gram Matrix\n",
    "gram_matrix_sample = gram_matrix[:5, :5]  # Small portion for verification\n",
    "\n",
    "# Save the detailed debugging information to a text file\n",
    "with open('question6.txt', 'w') as f:\n",
    "    f.write(f\"Sum of alpha: {alpha_sum}\\n\")\n",
    "    f.write(f\"Number of support vectors: {support_vectors_count}\\n\")\n",
    "    f.write(f\"First 5 support vector indices: {support_vectors_indices[:5]}\\n\")\n",
    "    f.write(f\"First 5 alpha values: {first_5_alphas}\\n\")\n",
    "    f.write(f\"Number of slack variables (margin violators): {slack_variable_count}\\n\")\n",
    "    f.write(f\"Regularization parameter (C): {regularisation_para_C}\\n\")\n",
    "    f.write(f\"Gram Matrix Sample (5x5):\\n{gram_matrix_sample}\\n\")\n",
    "\n",
    "# Print relevant info for quick reference\n",
    "print(f\"Sum of alpha: {alpha_sum}\")\n",
    "print(f\"Number of support vectors: {support_vectors_count}\")\n",
    "print(f\"First 5 alpha values: {first_5_alphas}\")\n",
    "print(f\"Number of margin violators (slack variables): {slack_variable_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9523bb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.0009765625, Validation Accuracy = 0.9746666666666667\n",
      "C = 0.00390625, Validation Accuracy = 0.9742222222222222\n",
      "C = 0.015625, Validation Accuracy = 0.9717777777777777\n",
      "C = 0.0625, Validation Accuracy = 0.9655555555555555\n",
      "C = 0.25, Validation Accuracy = 0.9624444444444444\n",
      "C = 1, Validation Accuracy = 0.962\n",
      "C = 4, Validation Accuracy = 0.9615555555555556\n",
      "C = 16, Validation Accuracy = 0.9602222222222222\n",
      "C = 64, Validation Accuracy = 0.96\n",
      "C = 256, Validation Accuracy = 0.9606666666666667\n",
      "C = 1024, Validation Accuracy = 0.9606666666666667\n",
      "Optimal C = 0.0009765625, Best Validation Accuracy = 0.9746666666666667\n"
     ]
    }
   ],
   "source": [
    "# Question 7\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the train data (replace 'train.csv' with the actual path)\n",
    "train_data = np.loadtxt('train.csv', delimiter=',')\n",
    "test_data = np.loadtxt('test.csv', delimiter=',')\n",
    "\n",
    "# Split train_data into features and labels\n",
    "X_train_full = train_data[:, 1:]  # All features\n",
    "y_train_full = train_data[:, 0]   # Class labels\n",
    "\n",
    "# Define the first 4000 samples as the training set\n",
    "X_train = X_train_full[:4000]\n",
    "y_train = y_train_full[:4000]\n",
    "\n",
    "# Use the remaining samples as the validation set\n",
    "X_val = X_train_full[4000:]\n",
    "y_val = y_train_full[4000:]\n",
    "\n",
    "# Function to train soft-margin SVM using CVXPY for a given C\n",
    "def svm_train_primal(X, y, C):\n",
    "    # Ensure that y is in {-1, 1}\n",
    "    y = np.where(y == 0, -1, 1)\n",
    "    \n",
    "    n_samples, n_features = X.shape\n",
    "    \n",
    "    # Variables for primal SVM\n",
    "    w = cp.Variable(n_features)\n",
    "    b = cp.Variable()\n",
    "    slack = cp.Variable(n_samples)\n",
    "    \n",
    "    # Objective: 1/2 ||w||^2 + C * sum(slack)\n",
    "    objective = cp.Minimize(0.5 * cp.norm(w, 2) ** 2 + C * cp.sum(slack))\n",
    "    \n",
    "    # Constraints: y_i (w^T x_i + b) >= 1 - slack_i, slack_i >= 0\n",
    "    constraints = [y[i] * (X[i] @ w + b) >= 1 - slack[i] for i in range(n_samples)]\n",
    "    constraints += [slack >= 0]\n",
    "    \n",
    "    # Formulate the problem and solve it\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    problem.solve()\n",
    "    \n",
    "    return w.value, b.value\n",
    "\n",
    "# Function to predict using the primal SVM\n",
    "def svm_predict_primal(X, w, b):\n",
    "    return np.sign(X @ w + b)\n",
    "\n",
    "# Grid search over C values\n",
    "C_values = [2 ** i for i in range(-10, 11, 2)]\n",
    "\n",
    "best_C = None\n",
    "best_accuracy = 0\n",
    "debug_info = []\n",
    "\n",
    "# Iterate over all values of C\n",
    "for C in C_values:\n",
    "    # Train the model using CVXPY with the current C\n",
    "    w, b = svm_train_primal(X_train, y_train, C)\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_val_pred = svm_predict_primal(X_val, w, b)\n",
    "    \n",
    "    # Convert the predictions from {-1, 1} back to {0, 1}\n",
    "    y_val_pred = np.where(y_val_pred == -1, 0, 1)\n",
    "    \n",
    "    # Calculate accuracy on the validation set\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    # Save debug info\n",
    "    debug_info.append({\n",
    "        \"C\": C,\n",
    "        \"Validation Accuracy\": accuracy,\n",
    "        \"Sum of w\": np.sum(w),\n",
    "        \"Bias (b)\": b,\n",
    "        \"First 5 Weights\": w[:5]\n",
    "    })\n",
    "    \n",
    "    print(f\"C = {C}, Validation Accuracy = {accuracy}\")\n",
    "    \n",
    "    # Update best C and accuracy if current one is better\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_C = C\n",
    "\n",
    "# Save all debug information to a text file\n",
    "with open('question7.txt', 'w') as f:\n",
    "    for info in debug_info:\n",
    "        f.write(f\"C = {info['C']}, Validation Accuracy = {info['Validation Accuracy']}\\n\")\n",
    "        f.write(f\"Sum of w: {info['Sum of w']}\\n\")\n",
    "        f.write(f\"Bias (b): {info['Bias (b)']}\\n\")\n",
    "        f.write(f\"First 5 weights of w: {info['First 5 Weights']}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "    # Save the best C and accuracy\n",
    "    f.write(f\"Optimal C = {best_C}, Best Validation Accuracy = {best_accuracy}\\n\")\n",
    "\n",
    "print(f\"Optimal C = {best_C}, Best Validation Accuracy = {best_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "594d9093",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chalyn03/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal C: 4\n",
      "Validation Accuracy: 96.35%\n",
      "Test Accuracy: 96.93%\n",
      "Sum of Model Coefficients: 0.01841335137515998\n",
      "Bias (Intercept): 1.0283074193860124\n",
      "First 5 Coefficients: [ 0.00062454 -0.01072562  0.03267166 -0.0184045   0.03379624]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chalyn03/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Question 8\n",
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the datasets and ensure the first column is the label and the rest are features\n",
    "train_data = pd.read_csv('train.csv', header=None)\n",
    "test_data = pd.read_csv('test.csv', header=None)\n",
    "\n",
    "# Split the datasets into features (X) and labels (y)\n",
    "X_train = train_data.iloc[:, 1:]  # All columns except the first one\n",
    "y_train = train_data.iloc[:, 0]   # First column is the label\n",
    "\n",
    "X_test = test_data.iloc[:, 1:]    # All columns except the first one\n",
    "y_test = test_data.iloc[:, 0]     # First column is the label\n",
    "\n",
    "# Split the training data into training and validation sets (80% training, 20% validation)\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the LinearSVC model using the optimal C value (adjust if different)\n",
    "optimal_C = 4\n",
    "svm_model = LinearSVC(C=optimal_C, max_iter=10000)\n",
    "svm_model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = svm_model.predict(X_val_split)\n",
    "\n",
    "# Calculate validation accuracy\n",
    "val_accuracy = accuracy_score(y_val_split, y_val_pred)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate test accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Debugging Information: Model coefficients and intercept\n",
    "coef_sum = svm_model.coef_.sum()\n",
    "intercept = svm_model.intercept_[0]\n",
    "first_5_coefficients = svm_model.coef_[0][:5]\n",
    "\n",
    "# Save detailed debug information to a text file\n",
    "with open('question8.txt', 'w') as f:\n",
    "    f.write(f\"Optimal C: {optimal_C}\\n\")\n",
    "    f.write(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\\n\")\n",
    "    f.write(f\"Test Accuracy: {test_accuracy * 100:.2f}%\\n\")\n",
    "    f.write(f\"Sum of Model Coefficients: {coef_sum}\\n\")\n",
    "    f.write(f\"Bias (Intercept): {intercept}\\n\")\n",
    "    f.write(f\"First 5 Coefficients: {first_5_coefficients}\\n\")\n",
    "\n",
    "# Print the results for quick reference\n",
    "print(f\"Optimal C: {optimal_C}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"Sum of Model Coefficients: {coef_sum}\")\n",
    "print(f\"Bias (Intercept): {intercept}\")\n",
    "print(f\"First 5 Coefficients: {first_5_coefficients}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
